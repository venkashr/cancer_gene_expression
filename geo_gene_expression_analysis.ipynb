{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEO (Gene Expression Omnibus) Data Analysis\n",
    "\n",
    "This notebook demonstrates how to download and analyze gene expression data from GEO.\n",
    "\n",
    "GEO is a public repository that archives high-throughput genomics data including:\n",
    "- Microarray data\n",
    "- RNA-seq data\n",
    "- ChIP-seq data\n",
    "- And more\n",
    "\n",
    "## Methods:\n",
    "1. Download data using GEOparse library\n",
    "2. Alternative: Download using NCBI E-utilities\n",
    "3. Process and normalize expression data\n",
    "4. Differential expression analysis\n",
    "5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install GEOparse pandas numpy matplotlib seaborn scipy scikit-learn statsmodels requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download GEO Dataset using GEOparse\n",
    "\n",
    "**Example datasets:**\n",
    "- GSE48558: Breast cancer vs normal tissue (Microarray)\n",
    "- GSE62944: Colorectal cancer (RNA-seq)\n",
    "- GSE68849: Prostate cancer (Microarray)\n",
    "- GSE183947: Lung cancer (RNA-seq)\n",
    "\n",
    "We'll use GSE48558 as an example (breast cancer microarray data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GEO dataset\n",
    "# This may take a few minutes depending on dataset size\n",
    "\n",
    "geo_id = \"GSE48558\"  # Breast cancer dataset\n",
    "\n",
    "print(f\"Downloading {geo_id} from GEO...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Download and parse\n",
    "gse = GEOparse.get_GEO(geo=geo_id, destdir=\"./geo_data\")\n",
    "\n",
    "print(f\"\\nDataset downloaded successfully!\")\n",
    "print(f\"Title: {gse.metadata['title'][0]}\")\n",
    "print(f\"Organism: {gse.metadata['organism'][0]}\")\n",
    "print(f\"Platform: {gse.metadata['platform_id'][0]}\")\n",
    "print(f\"Number of samples: {len(gse.gsms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Summary: {gse.metadata['summary'][0][:500]}...\\n\")\n",
    "\n",
    "# Get platform information\n",
    "platform_id = gse.metadata['platform_id'][0]\n",
    "print(f\"Platform ID: {platform_id}\")\n",
    "\n",
    "# List all samples\n",
    "print(f\"\\nSample IDs (first 10):\")\n",
    "sample_ids = list(gse.gsms.keys())\n",
    "print(sample_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sample metadata\n",
    "sample_metadata = []\n",
    "\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    # Extract relevant metadata\n",
    "    metadata_dict = {\n",
    "        'sample_id': gsm_name,\n",
    "        'title': gsm.metadata['title'][0] if 'title' in gsm.metadata else 'N/A',\n",
    "        'source': gsm.metadata['source_name_ch1'][0] if 'source_name_ch1' in gsm.metadata else 'N/A',\n",
    "    }\n",
    "    \n",
    "    # Extract characteristics\n",
    "    if 'characteristics_ch1' in gsm.metadata:\n",
    "        for char in gsm.metadata['characteristics_ch1']:\n",
    "            if ':' in char:\n",
    "                key, value = char.split(':', 1)\n",
    "                metadata_dict[key.strip()] = value.strip()\n",
    "    \n",
    "    sample_metadata.append(metadata_dict)\n",
    "\n",
    "# Create metadata DataFrame\n",
    "metadata_df = pd.DataFrame(sample_metadata)\n",
    "\n",
    "print(\"Sample Metadata:\")\n",
    "print(metadata_df.head(10))\n",
    "print(f\"\\nMetadata columns: {metadata_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sample groups (tumor vs normal)\n",
    "# This will vary by dataset - inspect the metadata to find the right column\n",
    "\n",
    "# For GSE48558, look for tissue type information\n",
    "print(\"Identifying sample groups...\\n\")\n",
    "\n",
    "# Check different possible column names\n",
    "possible_cols = ['tissue', 'sample type', 'tissue type', 'source', 'disease state', 'cell type']\n",
    "group_col = None\n",
    "\n",
    "for col in metadata_df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(metadata_df[col].value_counts())\n",
    "    \n",
    "# Let's create a condition column based on the data\n",
    "# For this dataset, we'll use 'tissue' column\n",
    "if 'tissue' in metadata_df.columns:\n",
    "    metadata_df['condition'] = metadata_df['tissue'].apply(\n",
    "        lambda x: 'Tumor' if 'tumor' in str(x).lower() or 'cancer' in str(x).lower() \n",
    "        else 'Normal'\n",
    "    )\n",
    "else:\n",
    "    # Fallback: use source column\n",
    "    metadata_df['condition'] = metadata_df['source'].apply(\n",
    "        lambda x: 'Tumor' if 'tumor' in str(x).lower() or 'cancer' in str(x).lower() \n",
    "        else 'Normal'\n",
    "    )\n",
    "\n",
    "print(\"\\nSample distribution:\")\n",
    "print(metadata_df['condition'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract expression data from all samples\n",
    "print(\"Extracting expression data...\")\n",
    "\n",
    "expression_data = {}\n",
    "\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    # Get the expression table\n",
    "    # For microarray data, we typically use 'VALUE' column\n",
    "    if hasattr(gsm.table, 'VALUE'):\n",
    "        expression_data[gsm_name] = gsm.table['VALUE']\n",
    "    elif 'VALUE' in gsm.table.columns:\n",
    "        expression_data[gsm_name] = gsm.table['VALUE']\n",
    "    else:\n",
    "        # Try to find the right column\n",
    "        # Common column names: VALUE, value, Signal, signal, Expression\n",
    "        for col in gsm.table.columns:\n",
    "            if 'value' in col.lower() or 'signal' in col.lower() or 'expression' in col.lower():\n",
    "                expression_data[gsm_name] = gsm.table[col]\n",
    "                break\n",
    "\n",
    "# Create expression DataFrame\n",
    "# Get gene IDs from the first sample\n",
    "first_sample = list(gse.gsms.values())[0]\n",
    "\n",
    "if 'ID_REF' in first_sample.table.columns:\n",
    "    gene_ids = first_sample.table['ID_REF']\n",
    "elif 'IDENTIFIER' in first_sample.table.columns:\n",
    "    gene_ids = first_sample.table['IDENTIFIER']\n",
    "else:\n",
    "    gene_ids = first_sample.table.index\n",
    "\n",
    "expression_df = pd.DataFrame(expression_data, index=gene_ids)\n",
    "\n",
    "print(f\"\\nExpression matrix shape: {expression_df.shape}\")\n",
    "print(f\"Number of probes/genes: {expression_df.shape[0]}\")\n",
    "print(f\"Number of samples: {expression_df.shape[1]}\")\n",
    "print(\"\\nFirst few rows and columns:\")\n",
    "print(expression_df.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Control and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric and handle missing values\n",
    "expression_df = expression_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(f\"Missing values: {expression_df.isna().sum().sum()}\")\n",
    "\n",
    "# Remove rows with too many missing values\n",
    "threshold = 0.2 * expression_df.shape[1]  # 20% of samples\n",
    "expression_df = expression_df.dropna(thresh=threshold)\n",
    "\n",
    "# Fill remaining missing values with row median\n",
    "expression_df = expression_df.apply(lambda row: row.fillna(row.median()), axis=1)\n",
    "\n",
    "print(f\"\\nAfter cleanup:\")\n",
    "print(f\"Expression matrix shape: {expression_df.shape}\")\n",
    "print(f\"Missing values: {expression_df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sample distribution boxplot\n",
    "# Select subset of samples for visualization\n",
    "sample_subset = expression_df.columns[:20]\n",
    "expression_df[sample_subset].boxplot(ax=axes[0], rot=90)\n",
    "axes[0].set_ylabel('Expression Value')\n",
    "axes[0].set_title('Expression Distribution by Sample (first 20)')\n",
    "axes[0].tick_params(axis='x', labelsize=6)\n",
    "\n",
    "# Overall distribution histogram\n",
    "axes[1].hist(expression_df.values.flatten(), bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Expression Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Overall Expression Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nExpression summary statistics:\")\n",
    "print(expression_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Log Transform if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is already log-transformed\n",
    "# Log-transformed data typically has values between 0-20\n",
    "# Raw intensity data can have very large values\n",
    "\n",
    "max_val = expression_df.max().max()\n",
    "min_val = expression_df.min().min()\n",
    "\n",
    "print(f\"Expression range: {min_val:.2f} to {max_val:.2f}\")\n",
    "\n",
    "if max_val > 100:  # Likely not log-transformed\n",
    "    print(\"Data appears to be raw intensity values. Applying log2 transformation...\")\n",
    "    expression_df_log = np.log2(expression_df + 1)  # Add 1 to avoid log(0)\n",
    "    print(f\"After log2 transformation: {expression_df_log.min().min():.2f} to {expression_df_log.max().max():.2f}\")\n",
    "else:\n",
    "    print(\"Data appears to be already log-transformed.\")\n",
    "    expression_df_log = expression_df.copy()\n",
    "\n",
    "# Use the log-transformed data for further analysis\n",
    "expression_final = expression_df_log.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Match Samples with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure sample order matches between expression and metadata\n",
    "common_samples = list(set(expression_final.columns) & set(metadata_df['sample_id']))\n",
    "\n",
    "print(f\"Samples in both expression data and metadata: {len(common_samples)}\")\n",
    "\n",
    "# Subset and order\n",
    "expression_final = expression_final[common_samples]\n",
    "metadata_df = metadata_df[metadata_df['sample_id'].isin(common_samples)]\n",
    "metadata_df = metadata_df.set_index('sample_id').loc[common_samples].reset_index()\n",
    "\n",
    "print(f\"\\nFinal dataset: {expression_final.shape[0]} genes × {expression_final.shape[1]} samples\")\n",
    "print(f\"\\nSample distribution:\")\n",
    "print(metadata_df['condition'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(expression_final.T)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create PCA DataFrame\n",
    "pca_df = pd.DataFrame(\n",
    "    pca_result,\n",
    "    columns=[f'PC{i+1}' for i in range(10)],\n",
    "    index=expression_final.columns\n",
    ")\n",
    "\n",
    "# Add condition information\n",
    "pca_df = pca_df.merge(\n",
    "    metadata_df[['sample_id', 'condition']].set_index('sample_id'),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "# Plot PCA\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PC1 vs PC2\n",
    "for condition, color in [('Tumor', 'red'), ('Normal', 'blue')]:\n",
    "    mask = pca_df['condition'] == condition\n",
    "    axes[0].scatter(\n",
    "        pca_df.loc[mask, 'PC1'],\n",
    "        pca_df.loc[mask, 'PC2'],\n",
    "        c=color,\n",
    "        label=condition,\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black'\n",
    "    )\n",
    "\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "axes[0].set_title(f'PCA: {geo_id} Samples')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scree plot\n",
    "axes[1].bar(range(1, 11), pca.explained_variance_ratio_ * 100)\n",
    "axes[1].set_xlabel('Principal Component')\n",
    "axes[1].set_ylabel('Variance Explained (%)')\n",
    "axes[1].set_title('Scree Plot')\n",
    "axes[1].set_xticks(range(1, 11))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Cumulative variance explained by first 3 PCs: {pca.explained_variance_ratio_[:3].sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Differential Expression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_differential_expression_geo(expression_df, metadata_df):\n",
    "    \"\"\"\n",
    "    Perform differential expression analysis on GEO data\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get sample IDs for each condition\n",
    "    tumor_samples = metadata_df[metadata_df['condition'] == 'Tumor']['sample_id'].values\n",
    "    normal_samples = metadata_df[metadata_df['condition'] == 'Normal']['sample_id'].values\n",
    "    \n",
    "    print(f\"Analyzing {len(tumor_samples)} tumor vs {len(normal_samples)} normal samples\\n\")\n",
    "    \n",
    "    for gene in expression_df.index:\n",
    "        tumor_expr = expression_df.loc[gene, tumor_samples].values\n",
    "        normal_expr = expression_df.loc[gene, normal_samples].values\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_tumor = np.mean(tumor_expr)\n",
    "        mean_normal = np.mean(normal_expr)\n",
    "        log2fc = mean_tumor - mean_normal\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = stats.ttest_ind(tumor_expr, normal_expr)\n",
    "        \n",
    "        results.append({\n",
    "            'Gene': gene,\n",
    "            'Mean_Tumor': mean_tumor,\n",
    "            'Mean_Normal': mean_normal,\n",
    "            'Log2FC': log2fc,\n",
    "            'T_statistic': t_stat,\n",
    "            'P_value': p_value\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Remove NaN p-values\n",
    "    results_df = results_df.dropna(subset=['P_value'])\n",
    "    \n",
    "    # Multiple testing correction\n",
    "    _, results_df['FDR'], _, _ = multipletests(\n",
    "        results_df['P_value'],\n",
    "        method='fdr_bh'\n",
    "    )\n",
    "    \n",
    "    # Add significance label\n",
    "    results_df['Significant'] = (results_df['FDR'] < 0.05) & (abs(results_df['Log2FC']) > 1)\n",
    "    \n",
    "    # Sort by p-value\n",
    "    results_df = results_df.sort_values('P_value')\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Perform differential expression\n",
    "print(\"Performing differential expression analysis...\")\n",
    "de_results = perform_differential_expression_geo(expression_final, metadata_df)\n",
    "\n",
    "# Summary\n",
    "n_significant = de_results['Significant'].sum()\n",
    "n_upregulated = ((de_results['Significant']) & (de_results['Log2FC'] > 0)).sum()\n",
    "n_downregulated = ((de_results['Significant']) & (de_results['Log2FC'] < 0)).sum()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DIFFERENTIAL EXPRESSION RESULTS ({geo_id})\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total genes analyzed: {len(de_results)}\")\n",
    "print(f\"Significant genes (FDR < 0.05, |Log2FC| > 1): {n_significant}\")\n",
    "print(f\"Upregulated in tumor: {n_upregulated}\")\n",
    "print(f\"Downregulated in tumor: {n_downregulated}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nTop 20 differentially expressed genes:\")\n",
    "print(de_results[['Gene', 'Log2FC', 'P_value', 'FDR', 'Significant']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Volcano Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for volcano plot\n",
    "de_results['-log10(FDR)'] = -np.log10(de_results['FDR'])\n",
    "\n",
    "# Create volcano plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Not significant\n",
    "not_sig = de_results[~de_results['Significant']]\n",
    "plt.scatter(not_sig['Log2FC'], not_sig['-log10(FDR)'], \n",
    "           c='gray', alpha=0.4, s=10, label='Not significant')\n",
    "\n",
    "# Significant and upregulated\n",
    "sig_up = de_results[(de_results['Significant']) & (de_results['Log2FC'] > 0)]\n",
    "plt.scatter(sig_up['Log2FC'], sig_up['-log10(FDR)'], \n",
    "           c='red', alpha=0.7, s=30, label=f'Upregulated ({len(sig_up)})')\n",
    "\n",
    "# Significant and downregulated\n",
    "sig_down = de_results[(de_results['Significant']) & (de_results['Log2FC'] < 0)]\n",
    "plt.scatter(sig_down['Log2FC'], sig_down['-log10(FDR)'], \n",
    "           c='blue', alpha=0.7, s=30, label=f'Downregulated ({len(sig_down)})')\n",
    "\n",
    "# Add threshold lines\n",
    "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1, alpha=0.5, label='FDR = 0.05')\n",
    "plt.axvline(-1, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.axvline(1, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Annotate top genes\n",
    "top_genes = de_results.nsmallest(10, 'FDR')\n",
    "for _, row in top_genes.iterrows():\n",
    "    plt.annotate(row['Gene'], \n",
    "                xy=(row['Log2FC'], row['-log10(FDR)']),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Log2 Fold Change (Tumor vs Normal)', fontsize=12)\n",
    "plt.ylabel('-log10(FDR)', fontsize=12)\n",
    "plt.title(f'Volcano Plot: {geo_id} Differential Expression', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Heatmap of Top Differentially Expressed Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 50 differentially expressed genes\n",
    "n_top_genes = min(50, len(de_results[de_results['Significant']]))\n",
    "\n",
    "if n_top_genes > 0:\n",
    "    top_genes = de_results.nsmallest(n_top_genes, 'FDR')['Gene'].values\n",
    "    \n",
    "    # Subset expression data\n",
    "    heatmap_data = expression_final.loc[top_genes]\n",
    "    \n",
    "    # Z-score normalize\n",
    "    heatmap_data_zscore = heatmap_data.sub(heatmap_data.mean(axis=1), axis=0).div(\n",
    "        heatmap_data.std(axis=1), axis=0\n",
    "    )\n",
    "    \n",
    "    # Create color map for conditions\n",
    "    col_colors = metadata_df.set_index('sample_id')['condition'].map(\n",
    "        {'Tumor': 'red', 'Normal': 'blue'}\n",
    "    )\n",
    "    \n",
    "    # Reorder to match heatmap columns\n",
    "    col_colors = col_colors.loc[heatmap_data_zscore.columns]\n",
    "    \n",
    "    # Create clustered heatmap\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    g = sns.clustermap(\n",
    "        heatmap_data_zscore,\n",
    "        col_colors=col_colors,\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        vmin=-3,\n",
    "        vmax=3,\n",
    "        figsize=(14, 10),\n",
    "        cbar_kws={'label': 'Z-score'},\n",
    "        yticklabels=True,\n",
    "        xticklabels=False,\n",
    "        row_cluster=True,\n",
    "        col_cluster=True\n",
    "    )\n",
    "    plt.suptitle(f'Top {n_top_genes} Differentially Expressed Genes ({geo_id})', \n",
    "                 y=0.98, fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No significant genes found for heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Expression Profiles of Top Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 6 genes\n",
    "n_plot = min(6, len(de_results[de_results['Significant']]))\n",
    "\n",
    "if n_plot > 0:\n",
    "    top_genes_plot = de_results.nsmallest(n_plot, 'FDR')['Gene'].values\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    tumor_samples = metadata_df[metadata_df['condition'] == 'Tumor']['sample_id'].values\n",
    "    normal_samples = metadata_df[metadata_df['condition'] == 'Normal']['sample_id'].values\n",
    "    \n",
    "    for idx, gene in enumerate(top_genes_plot):\n",
    "        gene_expr = expression_final.loc[gene]\n",
    "        \n",
    "        tumor_expr = gene_expr[tumor_samples].values\n",
    "        normal_expr = gene_expr[normal_samples].values\n",
    "        \n",
    "        # Box plot\n",
    "        bp = axes[idx].boxplot([tumor_expr, normal_expr], \n",
    "                               labels=['Tumor', 'Normal'], \n",
    "                               patch_artist=True)\n",
    "        \n",
    "        bp['boxes'][0].set_facecolor('red')\n",
    "        bp['boxes'][1].set_facecolor('blue')\n",
    "        \n",
    "        # Add points\n",
    "        axes[idx].scatter([1]*len(tumor_expr), tumor_expr, alpha=0.3, c='darkred', s=20)\n",
    "        axes[idx].scatter([2]*len(normal_expr), normal_expr, alpha=0.3, c='darkblue', s=20)\n",
    "        \n",
    "        # Get stats\n",
    "        gene_stats = de_results[de_results['Gene'] == gene].iloc[0]\n",
    "        \n",
    "        axes[idx].set_ylabel('Expression (log2)')\n",
    "        axes[idx].set_title(\n",
    "            f\"{gene}\\nLog2FC={gene_stats['Log2FC']:.2f}, FDR={gene_stats['FDR']:.2e}\"\n",
    "        )\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_plot, 6):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No significant genes to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = f\"geo_analysis_{geo_id}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save differential expression results\n",
    "de_results.to_csv(f'{output_dir}/differential_expression_results.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/differential_expression_results.csv\")\n",
    "\n",
    "# Save significant genes\n",
    "significant_genes = de_results[de_results['Significant']]\n",
    "significant_genes.to_csv(f'{output_dir}/significant_genes.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/significant_genes.csv ({len(significant_genes)} genes)\")\n",
    "\n",
    "# Save normalized expression matrix\n",
    "expression_final.to_csv(f'{output_dir}/normalized_expression.csv')\n",
    "print(f\"Saved: {output_dir}/normalized_expression.csv\")\n",
    "\n",
    "# Save metadata\n",
    "metadata_df.to_csv(f'{output_dir}/sample_metadata.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/sample_metadata.csv\")\n",
    "\n",
    "print(f\"\\nAll results saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Alternative: Download GEO Data Manually via FTP\n",
    "\n",
    "If GEOparse doesn't work or you want more control, you can download data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method: Download Series Matrix file directly\n",
    "def download_geo_series_matrix(geo_id, output_dir=\"geo_data_manual\"):\n",
    "    \"\"\"\n",
    "    Download GEO series matrix file directly from NCBI FTP\n",
    "    \"\"\"\n",
    "    import urllib.request\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct FTP URL\n",
    "    # Format: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSEnnnnnn/matrix/\n",
    "    geo_num = geo_id.replace('GSE', '')\n",
    "    series_prefix = geo_num[:-3] + 'nnn'\n",
    "    \n",
    "    base_url = f\"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE{series_prefix}/{geo_id}/matrix/\"\n",
    "    filename = f\"{geo_id}_series_matrix.txt.gz\"\n",
    "    url = base_url + filename\n",
    "    \n",
    "    print(f\"Downloading from: {url}\")\n",
    "    \n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, output_path)\n",
    "        print(f\"Downloaded to: {output_path}\")\n",
    "        \n",
    "        # Extract\n",
    "        with gzip.open(output_path, 'rb') as f_in:\n",
    "            with open(output_path.replace('.gz', ''), 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "        \n",
    "        print(f\"Extracted to: {output_path.replace('.gz', '')}\")\n",
    "        return output_path.replace('.gz', '')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (commented out - uncomment to use)\n",
    "# matrix_file = download_geo_series_matrix(\"GSE48558\")\n",
    "print(\"Alternative download method available (see code above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **Downloading GEO data** using GEOparse\n",
    "2. ✅ **Extracting sample metadata** and organizing samples\n",
    "3. ✅ **Processing expression data** (cleaning, normalization, log transformation)\n",
    "4. ✅ **Quality control** (missing values, distribution checks)\n",
    "5. ✅ **PCA analysis** for sample visualization\n",
    "6. ✅ **Differential expression analysis** with statistical testing\n",
    "7. ✅ **Multiple testing correction** (FDR)\n",
    "8. ✅ **Visualizations** (volcano plots, heatmaps, box plots)\n",
    "9. ✅ **Results export** for further analysis\n",
    "\n",
    "### Tips for Using GEO Data:\n",
    "\n",
    "1. **Browse GEO** at https://www.ncbi.nlm.nih.gov/geo/ to find datasets\n",
    "2. **Check sample metadata** carefully - column names vary by dataset\n",
    "3. **Verify data type** - microarray vs RNA-seq require different processing\n",
    "4. **Check preprocessing** - some datasets are already normalized\n",
    "5. **Read the paper** - understand experimental design and sample groups\n",
    "\n",
    "### Other Useful GEO Datasets:\n",
    "\n",
    "- **GSE62944**: Colorectal cancer RNA-seq\n",
    "- **GSE68849**: Prostate cancer microarray\n",
    "- **GSE183947**: Lung cancer RNA-seq\n",
    "- **GSE29431**: Gastric cancer microarray\n",
    "- **GSE50760**: Pancreatic cancer RNA-seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
